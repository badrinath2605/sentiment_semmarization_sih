{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIlA4vC5+tqOXbul9BWNbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badrinath2605/sentiment_semmarization_sih/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kjwK52SdPcS",
        "outputId": "8ce31aa2-24c6-4979-daa6-39e19636a627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b5488df8-6677-421c-0e45-a7126a719027)\n",
            "Torch: 2.8.0+cu126 CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi -L\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this as a single code cell (starts with ! so it's executed in shell)\n",
        "!pip install -q sentence-transformers transformers[torch] torch torchvision torchaudio scikit-learn nltk && python -m nltk.downloader punkt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGGqMZjqduO3",
        "outputId": "8a5fb234-6b50-4910-aea1-b9bfb411e055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hybrid_colab.py (paste in a cell)\n",
        "import gc, os, sys\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "nltk.download('punkt_tab')   # fallback (some tokenizers expect this)\n",
        "\n",
        "\n",
        "# ---------- CONFIG (colab-friendly defaults) ----------\n",
        "SENT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"   # good general SBERT (replace with legal SBERT if you want)\n",
        "# For Colab (T4 16GB) start with a small abstractive model; switch to LED only if you run out of options\n",
        "ABSTR_MODEL = \"t5-small\"   # alternatives: \"facebook/bart-large-cnn\" or \"allenai/led-base-16384\" (may OOM)\n",
        "TOP_K = 6\n",
        "MIN_SENT_LEN = 15\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CHUNK_OVERLAP = 50\n",
        "VERBOSE = True\n",
        "\n",
        "# ---------- Setup models ----------\n",
        "print(\"Device:\", DEVICE)\n",
        "sent_model = SentenceTransformer(SENT_MODEL)\n",
        "\n",
        "def load_abstractive(model_name):\n",
        "    try:\n",
        "        tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        model.to(DEVICE)\n",
        "        is_led = (\"led\" in model_name.lower()) or (\"longformer\" in model_name.lower())\n",
        "        if VERBOSE:\n",
        "            print(f\"Loaded {model_name} on {DEVICE} (LED-like={is_led})\")\n",
        "        return tok, model, is_led\n",
        "    except Exception as e:\n",
        "        print(\"Error loading abstractive model:\", e)\n",
        "        raise\n",
        "\n",
        "tokenizer, abstr_model, abstr_is_led = load_abstractive(ABSTR_MODEL)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def split_sentences(text, min_len=MIN_SENT_LEN):\n",
        "    sents = [s.strip() for s in sent_tokenize(text)]\n",
        "    sents = [s for s in sents if len(s) >= min_len]\n",
        "    return sents\n",
        "\n",
        "def embed_sentences(sents):\n",
        "    return sent_model.encode(sents, convert_to_numpy=True, show_progress_bar=False)\n",
        "\n",
        "def extract_by_centroid(text, top_k=TOP_K):\n",
        "    sents = split_sentences(text)\n",
        "    if not sents:\n",
        "        return \"\", []\n",
        "    embs = embed_sentences(sents)\n",
        "    centroid = embs.mean(axis=0, keepdims=True)\n",
        "    sims = cosine_similarity(embs, centroid).squeeze()\n",
        "    top_idx = np.argsort(-sims)[:min(top_k, len(sents))]\n",
        "    chosen_idx = sorted(top_idx)\n",
        "    chosen = [(int(i), sents[i]) for i in chosen_idx]\n",
        "    summary = \" \".join([s for _, s in chosen])\n",
        "    return summary, chosen\n",
        "\n",
        "def chunk_text_for_tokenizer(text, tokenizer, max_tokens, overlap=CHUNK_OVERLAP):\n",
        "    ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "    if len(ids) <= max_tokens:\n",
        "        return [text]\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(ids):\n",
        "        end = start + max_tokens\n",
        "        chunk_ids = ids[start:end]\n",
        "        chunk_text = tokenizer.decode(chunk_ids, clean_up_tokenization_spaces=True)\n",
        "        chunks.append(chunk_text)\n",
        "        if end >= len(ids):\n",
        "            break\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def set_led_global_attention(input_ids):\n",
        "    mask = torch.zeros_like(input_ids)\n",
        "    mask[:, 0] = 1\n",
        "    return mask\n",
        "\n",
        "def generate_with_model(texts, tokenizer, model, is_led, max_new_tokens=120, num_beams=4, batch_size=4):\n",
        "    device = DEVICE\n",
        "    summaries = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "            input_ids = enc[\"input_ids\"].to(device)\n",
        "            attention_mask = enc[\"attention_mask\"].to(device)\n",
        "            gen_kwargs = dict(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                              max_new_tokens=max_new_tokens, num_beams=num_beams, early_stopping=True)\n",
        "            if is_led:\n",
        "                gen_kwargs[\"global_attention_mask\"] = set_led_global_attention(input_ids)\n",
        "            outs = model.generate(**gen_kwargs)\n",
        "            decoded = [tokenizer.decode(o, skip_special_tokens=True, clean_up_tokenization_spaces=True) for o in outs]\n",
        "            summaries.extend(decoded)\n",
        "    return summaries\n",
        "\n",
        "def hybrid_summarize(long_text, extract_method=\"centroid\", top_k=TOP_K,\n",
        "                     abstr_max_new_tokens=120, beam_size=4):\n",
        "    if extract_method==\"kmeans\":\n",
        "        extracted_text, provenance = extract_by_kmeans(long_text, top_k)\n",
        "    else:\n",
        "        extracted_text, provenance = extract_by_centroid(long_text, top_k)\n",
        "    if VERBOSE:\n",
        "        print(f\"Extracted {len(provenance)} sentences.\")\n",
        "    if not extracted_text:\n",
        "        return \"\", provenance\n",
        "\n",
        "    tok = tokenizer; model = abstr_model; is_led = abstr_is_led\n",
        "    model_max = tok.model_max_length if getattr(tok, \"model_max_length\", None) else 1024\n",
        "    abstr_max_input = model_max - 32\n",
        "\n",
        "    enc_len = len(tok.encode(extracted_text, add_special_tokens=False))\n",
        "    if enc_len <= abstr_max_input:\n",
        "        if VERBOSE: print(\"Fits model, generating...\")\n",
        "        final = generate_with_model([extracted_text], tok, model, is_led,\n",
        "                                    max_new_tokens=abstr_max_new_tokens, num_beams=beam_size)[0]\n",
        "        return final, provenance\n",
        "\n",
        "    if VERBOSE: print(f\"Too long for model ({enc_len} tokens). Chunking...\")\n",
        "    chunks = chunk_text_for_tokenizer(extracted_text, tok, abstr_max_input)\n",
        "    if VERBOSE: print(f\"{len(chunks)} chunk(s). Summarizing chunks...\")\n",
        "    chunk_summaries = generate_with_model(chunks, tok, model, is_led,\n",
        "                                          max_new_tokens=abstr_max_new_tokens, num_beams=beam_size)\n",
        "    if len(chunk_summaries) == 1:\n",
        "        final = chunk_summaries[0]\n",
        "    else:\n",
        "        combined = \" \".join(chunk_summaries)\n",
        "        comb_len = len(tok.encode(combined, add_special_tokens=False))\n",
        "        if comb_len <= abstr_max_input:\n",
        "            if VERBOSE: print(\"Combining chunks and doing final rewrite...\")\n",
        "            final = generate_with_model([combined], tok, model, is_led,\n",
        "                                        max_new_tokens=abstr_max_new_tokens, num_beams=beam_size)[0]\n",
        "        else:\n",
        "            if VERBOSE: print(\"Combined too long: returning concatenated chunk summaries.\")\n",
        "            final = \" \".join(chunk_summaries)\n",
        "    # free mem\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "    return final, provenance\n",
        "\n",
        "# Fallback kmeans (if user chooses)\n",
        "def extract_by_kmeans(text, top_k=TOP_K):\n",
        "    sents = split_sentences(text)\n",
        "    if not sents:\n",
        "        return \"\", []\n",
        "    embs = embed_sentences(sents)\n",
        "    n_clusters = min(top_k, len(sents))\n",
        "    km = KMeans(n_clusters=n_clusters, random_state=42).fit(embs)\n",
        "    centers = km.cluster_centers_\n",
        "    labels = km.labels_\n",
        "    chosen = []\n",
        "    for c in range(n_clusters):\n",
        "        cluster_idx = np.where(labels == c)[0]\n",
        "        if len(cluster_idx)==0: continue\n",
        "        cluster_embs = embs[cluster_idx]\n",
        "        sims = cosine_similarity(cluster_embs, centers[c].reshape(1,-1)).squeeze()\n",
        "        best_local = cluster_idx[int(np.argmax(sims))]\n",
        "        chosen.append(best_local)\n",
        "    chosen_sorted = sorted(chosen)\n",
        "    chosen_list = [(int(i), sents[i]) for i in chosen_sorted]\n",
        "    summary = \" \".join([s for _, s in chosen_list])\n",
        "    return summary, chosen_list\n",
        "\n",
        "# ---------- Example usage ----------\n",
        "sample_text = \"\"\"Paste your long legal document here. Or load from Drive:\n",
        "with open('/content/yourfile.txt') as f: text = f.read()\n",
        "\"\"\"\n",
        "# run the pipeline\n",
        "final_summary, provenance = hybrid_summarize(sample_text, extract_method=\"centroid\", top_k=6)\n",
        "print(\"\\nFINAL SUMMARY:\\n\", final_summary)\n",
        "print(\"\\nPROVENANCE:\")\n",
        "for idx, sent in provenance:\n",
        "    print(idx, \":\", sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvWABv1Je9M9",
        "outputId": "627272e1-d2b2-41ad-8268-3fcffc236cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loaded t5-small on cuda (LED-like=False)\n",
            "Extracted 2 sentences.\n",
            "Fits model, generating...\n",
            "\n",
            "FINAL SUMMARY:\n",
            " .txt') as f: text = f.read().\n",
            "\n",
            "PROVENANCE:\n",
            "0 : Paste your long legal document here.\n",
            "1 : Or load from Drive:\n",
            "with open('/content/yourfile.txt') as f: text = f.read()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import nltk\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "\n",
        "# make sure punkt is ready\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# 1. Load models\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")   # fast embeddings\n",
        "abstractive_model = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# 2. Split text and pick key sentences (extractive step)\n",
        "def extract_key_sentences(text, top_k=3):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    if len(sentences) <= top_k:\n",
        "        return sentences\n",
        "    embeddings = embedder.encode(sentences)\n",
        "    centroid = np.mean(embeddings, axis=0)\n",
        "    print(centroid)\n",
        "    print(embeddings)\n",
        "    scores = cosine_similarity([centroid], embeddings)[0]\n",
        "    print(scores)\n",
        "    ranked = [s for _, s in sorted(zip(scores, sentences), reverse=True)]\n",
        "    print(ranked)\n",
        "    return ranked[:top_k]\n",
        "\n",
        "# 3. Abstractive rewrite\n",
        "def abstractive_summarize(sentences, max_len=80):\n",
        "    joined = \" \".join(sentences)\n",
        "    result = abstractive_model(joined, max_length=max_len, min_length=20, do_sample=False)\n",
        "    return result[0][\"summary_text\"]\n",
        "\n",
        "# 4. Full hybrid pipeline (now also returns extracted sentences)\n",
        "def hybrid_summarize(text, top_k=3, show_extracts=True):\n",
        "    key_sentences = extract_key_sentences(text, top_k=top_k)\n",
        "    summary = abstractive_summarize(key_sentences)\n",
        "    if show_extracts:\n",
        "        print(\"\\n🔎 Key Extracted Sentences:\")\n",
        "        for i, s in enumerate(key_sentences, 1):\n",
        "            print(f\"{i}. {s}\")\n",
        "    return summary\n",
        "\n",
        "# 5. Accuracy check (with reference summary)\n",
        "def check_accuracy(text, reference, top_k=3):\n",
        "    pred = hybrid_summarize(text, top_k)\n",
        "    scores = rouge.compute(predictions=[pred], references=[reference])\n",
        "    return pred, scores\n",
        "\n",
        "# -------------------------------\n",
        "# 🔹 TEST WITH NEW EXAMPLES\n",
        "# -------------------------------\n",
        "\n",
        "example_text = \"\"\"\n",
        "The new environmental regulation draft requires companies to report carbon emissions every quarter.\n",
        "However, the section on penalty clauses is vague and does not specify fines clearly.\n",
        "Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective.\n",
        "Others support the draft, saying it encourages gradual compliance rather than harsh punishment.\n",
        "\"\"\"\n",
        "\n",
        "reference_summary = \"The draft regulation mandates quarterly emission reports but lacks clarity on penalties and enforcement.\"\n",
        "\n",
        "# run summarizer\n",
        "summary, metrics = check_accuracy(example_text, reference_summary, top_k=3)\n",
        "\n",
        "print(\"\\n📝 Model Summary:\\n\", summary)\n",
        "print(\"\\n📊 ROUGE Metrics:\\n\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJobjiOtfL9a",
        "outputId": "d55a5c67-8cd2-48cf-b3ff-644831132633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "Device set to use cuda:0\n",
            "Your max_length is set to 80, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔎 Key Extracted Sentences:\n",
            "1. Others support the draft, saying it encourages gradual compliance rather than harsh punishment.\n",
            "2. Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective.\n",
            "3. \n",
            "The new environmental regulation draft requires companies to report carbon emissions every quarter.\n",
            "\n",
            "📝 Model Summary:\n",
            " Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective. Others support the draft, saying it encourages gradual compliance rather than harsh punishment.\n",
            "\n",
            "📊 ROUGE Metrics:\n",
            " {'rouge1': np.float64(0.14634146341463417), 'rouge2': np.float64(0.05128205128205129), 'rougeL': np.float64(0.0975609756097561), 'rougeLsum': np.float64(0.0975609756097561)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJLfriaD4u6x",
        "outputId": "911b95bd-e4f8-44b4-aed0-73f26be7516a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6LLNmIx4x4N",
        "outputId": "95235a04-e402-41a2-a266-df2f136b3a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=739187de051d61ab355b4c21927dfbf29e067b42024a1e0a1e229f3c4242f0fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_key_sentences(text, top_k=3):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    if len(sentences) <= top_k:\n",
        "        return sentences\n",
        "    embeddings = embedder.encode(sentences)\n",
        "    centroid = np.mean(embeddings, axis=0)\n",
        "    print(\"centroid\",centroid)\n",
        "    print(\"embeddings\",embeddings)\n",
        "    scores = cosine_similarity([centroid], embeddings)[0]\n",
        "    print(\"scores\",scores)\n",
        "    ranked = [s for _, s in sorted(zip(scores, sentences), reverse=True)]\n",
        "    print(\"ranked\",ranked)\n",
        "    return ranked[:top_k]\n"
      ],
      "metadata": {
        "id": "tp0G6bNh6Qtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"\"\"\n",
        "The new environmental regulation draft requires companies to report carbon emissions every quarter.\n",
        "However, the section on penalty clauses is vague and does not specify fines clearly.\n",
        "Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective.\n",
        "Others support the draft, saying it encourages gradual compliance rather than harsh punishment.\n",
        "\"\"\"\n",
        "\n",
        "reference_summary = \"The draft regulation mandates quarterly emission reports but lacks clarity on penalties and enforcement.\"\n",
        "\n",
        "# run summarizer\n",
        "summary, metrics = check_accuracy(example_text, reference_summary, top_k=3)\n",
        "\n",
        "print(\"\\n📝 Model Summary:\\n\", summary)\n",
        "print(\"\\n📊 ROUGE Metrics:\\n\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSZMhx5i5WSd",
        "outputId": "f3b2f25d-f695-4b1c-cdaf-1daf46687304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 80, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "centroid [ 7.80226663e-03  5.72779067e-02  1.44031523e-02  4.09040367e-03\n",
            "  5.34865782e-02  4.86362427e-02 -5.39609864e-02 -6.64051920e-02\n",
            " -1.80745032e-04  3.37831527e-02  2.74890084e-02  3.70184258e-02\n",
            " -7.62730511e-03  3.72977778e-02  2.42742766e-02 -2.34567225e-02\n",
            "  3.52557711e-02 -1.13050584e-02 -2.87542585e-03  1.23913437e-02\n",
            "  3.89079675e-02  2.39060614e-02  1.60450414e-02  7.87554979e-02\n",
            " -1.32592302e-02 -3.64009142e-02 -3.44943851e-02  2.07959525e-02\n",
            " -7.84841832e-04 -2.29594409e-02 -4.50914018e-02  6.70173019e-02\n",
            " -2.12794635e-02  3.16747017e-02  5.29159512e-03 -9.14734509e-03\n",
            "  2.85529979e-02 -1.07273525e-02 -5.57542662e-05 -2.39412710e-02\n",
            " -2.17141267e-02 -1.46933766e-02 -5.04318513e-02  4.30593342e-02\n",
            " -5.19973878e-03 -5.48326643e-05 -7.29370490e-03 -5.17267622e-02\n",
            " -9.50782746e-02 -2.03482620e-02  4.98113548e-03  8.04084446e-03\n",
            " -1.16994279e-02  9.92887001e-03 -1.72812231e-02 -6.22903258e-02\n",
            " -1.19393338e-02 -4.64573875e-02  3.14650685e-02 -3.33945416e-02\n",
            " -1.87320244e-02 -6.89277649e-02 -2.80244239e-02 -1.87927969e-02\n",
            "  4.13394086e-02  2.00989135e-02 -2.68047359e-02 -5.83855584e-02\n",
            " -3.56753021e-02  4.28317394e-03 -5.55461384e-02 -1.59461442e-02\n",
            "  6.68351725e-03  1.19479261e-02 -3.15645412e-02  3.68692242e-02\n",
            " -4.42501530e-02  7.61397928e-02  9.77636054e-02 -8.93176347e-02\n",
            " -3.17789912e-02 -2.22358061e-03  3.44762243e-02 -1.55770313e-03\n",
            " -3.84347560e-03 -1.78133771e-02 -9.61556938e-03 -5.08225039e-02\n",
            "  2.96307728e-02  2.24505179e-02  2.44341232e-02 -4.50843573e-03\n",
            "  9.29424018e-02 -3.84683944e-02 -4.64970954e-02  8.85998644e-03\n",
            "  2.13506110e-02 -1.61853470e-02 -2.42965426e-02 -2.18581520e-02\n",
            "  2.52781361e-02  2.13665701e-03 -1.86123885e-02 -1.19836703e-02\n",
            " -2.68825460e-02 -6.40175343e-02  2.23495085e-02 -4.55350801e-02\n",
            " -4.03643884e-02  2.59050559e-02  2.05074251e-02  3.71954553e-02\n",
            "  3.46963219e-02 -2.50435323e-02 -2.01978590e-02  6.64282367e-02\n",
            " -5.43603068e-03  4.47138287e-02  4.06045318e-02  5.03592268e-02\n",
            " -3.76107767e-02  7.62001332e-03 -7.97193963e-04  1.24468310e-02\n",
            "  8.27252679e-03 -8.97520594e-03 -3.46674882e-02 -2.62090204e-33\n",
            "  4.72432151e-02 -3.92743610e-02 -2.65414193e-02  3.19029111e-03\n",
            " -2.63355933e-02 -3.33393402e-02  1.20778745e-02 -3.67635861e-02\n",
            "  3.68438885e-02  6.63727988e-03 -1.18238116e-02 -3.99902016e-02\n",
            "  3.75649780e-02  5.16780019e-02  7.35306069e-02  1.53191816e-02\n",
            " -3.79523337e-02  8.13979656e-02  3.26575302e-02  2.38841195e-02\n",
            "  4.10579368e-02 -5.43051995e-02 -8.85570887e-03 -1.75885614e-02\n",
            " -3.02501395e-02 -3.19195725e-02 -2.03997195e-02 -5.80039341e-03\n",
            " -8.90169293e-03  2.12346315e-02  2.21754052e-02  3.29635590e-02\n",
            "  5.62174134e-02  8.77897069e-03  2.71867607e-02  4.63061482e-02\n",
            " -9.46884230e-03  2.77909432e-02 -1.28566772e-02  1.12623861e-02\n",
            " -5.88710606e-03  5.53420857e-02  7.84963369e-04 -4.07392904e-03\n",
            "  5.28007895e-02 -1.85726229e-02 -2.35704007e-03 -3.26531939e-02\n",
            " -3.29945758e-02  9.04165953e-03  8.65571573e-03  3.96452993e-02\n",
            " -1.30603975e-02 -1.68755539e-02  4.32772562e-02  7.79212918e-03\n",
            " -1.34826265e-02 -5.19413222e-03 -1.92568805e-02 -7.88138248e-03\n",
            " -1.23604890e-02  3.71369310e-02 -5.17587624e-02  5.45299277e-02\n",
            "  8.58856738e-03  5.08610345e-02 -3.67866307e-02  3.97186019e-02\n",
            " -6.66769687e-04 -6.14421666e-02  1.59441065e-02 -1.96545776e-02\n",
            " -8.72458704e-03 -1.11974366e-02 -7.16069192e-02 -4.92294393e-02\n",
            "  4.78941910e-02 -1.14825107e-02  4.72348258e-02 -4.90594618e-02\n",
            "  2.39187311e-02 -2.62498893e-02  2.82371119e-02  2.98783928e-03\n",
            "  1.71275549e-02 -3.45151573e-02  6.83920905e-02  4.77068387e-02\n",
            " -2.11727619e-03 -2.28339694e-02 -1.23691233e-02 -1.92648694e-02\n",
            "  1.67296920e-03  3.55576053e-02  2.67432090e-02  1.07915267e-33\n",
            "  9.44307819e-03  5.72904106e-03  7.84938224e-03  1.16361361e-02\n",
            " -2.04847790e-02  7.48555781e-03 -3.11493538e-02 -4.66094464e-02\n",
            "  6.17110580e-02 -5.82971657e-03 -2.99791154e-02 -2.66100205e-02\n",
            " -5.70094623e-02  4.79061380e-02 -1.98095245e-03 -7.24195093e-02\n",
            " -7.76373893e-02 -1.61889270e-02 -2.17509475e-02  1.67057943e-02\n",
            "  2.60169245e-02 -4.02735509e-02 -1.78626664e-02  9.47939083e-02\n",
            " -7.07217306e-03  1.43965427e-02 -4.83076721e-02 -3.86860780e-02\n",
            "  2.10131183e-02 -9.59689636e-03 -4.10665572e-03  4.43907548e-03\n",
            " -4.82388400e-02  1.01723736e-02  1.13086263e-02 -1.11988410e-01\n",
            " -1.22517589e-02  4.38469425e-02 -9.24405921e-03  3.21855471e-02\n",
            "  8.22907500e-03  1.95895173e-02 -4.84113172e-02  2.32692529e-03\n",
            " -4.04703766e-02 -4.72165225e-03  4.17042002e-02 -5.20406961e-02\n",
            "  1.52869625e-02  2.33456213e-03 -1.85698755e-02  4.75755055e-03\n",
            " -1.24752875e-02  3.52889597e-02 -1.20992530e-02 -7.30771758e-03\n",
            "  4.43033241e-02 -1.41931335e-02  4.72603701e-02  2.23334469e-02\n",
            "  3.71764116e-02  5.33163175e-02  1.40540786e-02 -9.57786292e-03\n",
            "  8.41623247e-02 -3.12176086e-02 -2.51071844e-02  7.53352977e-03\n",
            "  6.20929934e-02  3.34231555e-02  1.20581193e-02 -6.86622262e-02\n",
            "  1.81413535e-02 -8.86625424e-03  1.98454075e-02 -2.04296149e-02\n",
            "  3.55715081e-02 -3.16768587e-02 -5.20557500e-02  2.10475251e-02\n",
            "  1.97572131e-02 -6.02429546e-03 -1.71567053e-02  3.66441086e-02\n",
            "  2.51632184e-04 -3.84047069e-02  1.05657792e-02 -5.17037287e-02\n",
            " -6.66049030e-03  4.62213606e-02 -3.82268615e-02 -5.19061536e-02\n",
            " -2.83291610e-03  1.67581663e-02 -3.99567708e-02 -2.18769678e-08\n",
            " -2.68675201e-02  2.56292038e-02 -1.16793849e-02  4.80601639e-02\n",
            "  3.16797011e-02  4.98755984e-02  3.89511883e-02 -2.10781693e-02\n",
            "  5.56949861e-02 -1.85353961e-03  6.83725178e-02  4.27401019e-03\n",
            " -7.97590334e-03 -2.80759670e-02 -4.04391252e-02  2.84669623e-02\n",
            " -5.19053824e-03  1.27155473e-02 -3.20084281e-02  2.50682496e-02\n",
            " -7.90044367e-02  1.96608100e-02 -3.78295071e-02 -1.73793919e-02\n",
            "  3.50403972e-02  1.08880382e-02 -1.19236894e-02  7.84335136e-02\n",
            "  4.22395393e-02  5.49376160e-02 -2.23099929e-03  1.27723441e-02\n",
            "  5.73626347e-02  1.75016448e-02 -5.28916679e-02 -5.16877230e-03\n",
            " -5.34897856e-03  3.35702207e-03  3.88372317e-03 -5.26476000e-03\n",
            " -3.00112236e-02  3.65969352e-02  1.92648824e-02  2.98012067e-02\n",
            "  1.46183390e-02 -4.32419553e-02 -5.68282083e-02 -1.17032249e-02\n",
            " -4.08609286e-02  3.33140837e-03 -1.77397672e-03 -6.38407748e-03\n",
            "  5.76564223e-02  2.60122865e-02  2.30105147e-02  7.47524872e-02\n",
            " -7.14804046e-05 -2.40970850e-02 -1.43772475e-02 -2.83737108e-02\n",
            "  5.36677279e-02  1.93061344e-02  5.92763238e-02 -9.82057303e-03]\n",
            "embeddings [[-0.00069144  0.04257916  0.02596801 ...  0.02580919  0.04672389\n",
            "  -0.01625232]\n",
            " [ 0.06381147  0.05320949  0.04076647 ...  0.04152294  0.08247139\n",
            "  -0.0960706 ]\n",
            " [ 0.01202463  0.07565435 -0.01361155 ... -0.01812763  0.02884726\n",
            "   0.06068651]\n",
            " [-0.0439356   0.05766861  0.00448968 ...  0.02802004  0.07906274\n",
            "   0.01235413]]\n",
            "scores [0.6279323  0.57468    0.7704625  0.77834344]\n",
            "ranked ['Others support the draft, saying it encourages gradual compliance rather than harsh punishment.', 'Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective.', '\\nThe new environmental regulation draft requires companies to report carbon emissions every quarter.', 'However, the section on penalty clauses is vague and does not specify fines clearly.']\n",
            "\n",
            "🔎 Key Extracted Sentences:\n",
            "1. Others support the draft, saying it encourages gradual compliance rather than harsh punishment.\n",
            "2. Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective.\n",
            "3. \n",
            "The new environmental regulation draft requires companies to report carbon emissions every quarter.\n",
            "\n",
            "📝 Model Summary:\n",
            " Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective. Others support the draft, saying it encourages gradual compliance rather than harsh punishment.\n",
            "\n",
            "📊 ROUGE Metrics:\n",
            " {'rouge1': np.float64(0.14634146341463417), 'rouge2': np.float64(0.05128205128205129), 'rougeL': np.float64(0.0975609756097561), 'rougeLsum': np.float64(0.0975609756097561)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "he new environmental regulation draft requires companies to report carbon emissions every quarter.\n",
        "However, the section on penalty clauses is vague and does not specify fines clearly.\n",
        "Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective.\n",
        "Others support the draft, saying it encourages gradual compliance rather than harsh punishment."
      ],
      "metadata": {
        "id": "FqGf6M2X7Pm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Many stakeholders argue that without strict enforcement mechanisms, the draft will not be effective. Others support the draft, saying it encourages gradual\n",
        "compliance rather than harsh punishment.\n"
      ],
      "metadata": {
        "id": "bKwPY1Lx7MXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The draft regulation mandates quarterly emission reports but lacks clarity on penalties and enforcement."
      ],
      "metadata": {
        "id": "I6V1dz0H73vU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}